***cấu hình raid -gắn ô cứng3


- gắn thêm 3 ổ cứng giống nhau và đặt tên lần lượt là sdv, sdc, sdd

lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT   ---liệt kê, kiểm tra xem các ổ cứng được thêm vào chưa

sudo mdadm --create --verbose /dev/md0 --level=5 --raid-device=3 /dev/sdb /dev/sdc /dev/sdd
---gắn thêm 3 ổ cứng có tên là sdb,sdc,sdd vừa  tạo /dev/md0


sudo mkfs.ext4 -F /dev/md0


sudo mkdir -p /mnt/md0      --- tạo thư mục /mnt/md0


sudo mount /dev/md0  /mnt/md0


df -h -x devtmpfs -x tmpfs    --- kiểm tra xem mount được chưa
 

sudo mdadm --detail --scan  | sudo tee -a /etc/mdadm/mdadm.conf


sudo update-initramfs -u

echo '/dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0' | sudo t -a /etc/fstab









---- lý thuyết LVM
1. Logical Volume Management(LVM)

- được sử dụng để tạo ra nhiều ổ đĩa logic

- nó cho phép cac bộ phận logic được thay đổi kích thước (tăng  hoặc giảm) theo ý muốn của người quản trị

- cấu trúc của LVM
+  một hoạc nhiều đĩa cứng hoặc phân vùng được định cấu hình là physical volume(PV)
+ một volume group(VG) được tạo bằng cách sử dụng một hoặc nhiều khối vật lí
+ nhiều logical volume có thể tạo trong một volume group


2. Các bước để quản lí và tạo LVM bằng các lệnh vgcreate, lvcreate và lvextend

2.1. Tạo Physical volume, volume groups, logical volume


-- sử dụng câu lệnh sau để tạo physical volume (PV) trên /dev/sdb, /dev/sdc, /dev/sdd

pvcreate /dev/sdb /dev/sdc /dev/sdd


-- liệt kê các physical volume(PV) mới được tạo chạy câu lệnh sau:

pvs

==> ý nghĩa : PV: đĩa được sử dụng 
	      PFree: kích thước đĩa vật lí(kích thước PV)  
	    
--- để có được thông tin chi tiết về physical volume(PV) /dev/sdb. chúng ta thực hiện lệnh sau:

pvdisplay /dev/sdb


==> lưu ý : khí chúng ta có 2 ổ đĩa hay nhiều ổ đĩa để tạo một volume mà một đĩa ở volume bị mất thì dẫn tới volume đó mất luôn, vì thế ohair chạy LVM trên Raid hoặc dùng tính năng RAID của LVM để có khả năng dung lỗi



2.1.2. Tạo Volume group

---Để tạo volume group với tên vg0 bằng cách sử dụng /dev/sdb và /dev/sdc . chúng ta thực hiện như sau:

vgcreate vg0 /dev/sdb /dev/sdc 

- thực hiện lệnh sau để xem thông tin group vừa tạo:

vgdisplay vg0

==> ý nghĩa: vì vg0 chưas 2 đĩa 10G nên VG Size= 19,99GB

    VG Name: Tên Volume Group.
    Format: Kiến trúc LVM được sử dụng.
    VG Access: Volume Group có thể đọc và viết và sẵn sàng để sử dụng.
    VG Status: Volume Group có thể được định cỡ lại, chúng ta có thể mở rộng thêm nếu cần thêm dung lượng.
    PE Size: Mở rộng Physical, Kích thước cho đĩa có thể được xác định bằng kích thước PE hoặc GB, 4MB là kích thước PE mặc định của LVM
    Total PE: Dung lượng Volume Group có
    Alloc PE: Tổng PE đã sử dụng
    Free PE: Tổng PE chưa được sử dụng


----Chúng ta có thể kiểm tra số lượng physical volume(PV) dùng để tạo volume group như sau:

sử  dụng câu lệnh : vgs 

---Trong đó:

    VG: Tên Volume Group
    #PV: Physical Volume sử dụng trong Volume Group
    VFree: Hiển thị không gian trống có sẵn trong Volume Group
    VSize: Tổng kích thước của Volume Group
    #LV: Logical Volume nằm trong volume group
    #SN: Số lượng Snapshot của volume group
    Attr: Trạng thái của Volume group có thể ghi, có thể đọc, có thể thay đổi,
    
    
2.1.3. Tạo Logical Volume


---Chúng ta sẽ tạo 2 logical volume với tên projects có dung lượng là 10GB và backups sử dụng toàn bộ dung lượng còn lại của volume group. Chúng ta chạy lệnh sau:

câu lệnh: lvcreate -n projects -L 10G vg0 ---- tạo logical volume với tên projects

câu lệnh: lvcreate -n backups -l 100%FREE vg0 ---- tạo backups 

---Trong đó:

    -n: Sử dụng chỉ ra tên của logical volume cần tạo.
    -L: Sử dụng chỉ một kích thước cố định.
    -l: Sử dụng chỉ phần trăm của không gian còn lại trong volume group.
    
    
---  Chạy lệnh sau để xem danh sách logical volume vừa được tạo:
    
câu lệnh: lvs 

---Ý nghĩa các trường của lvs:

    LV: Tên logical volume
    %Data: Phần trăm dung lượng logical volume được sử dụng
    Lsize: Kích thước của logical volume 
    
    
 ----Sử dụng lệnh sau để hiển thị thông tin chi tiết của các logical volume:
 câu lệnh: lvdisplay vg0/projects
         : lvdisplay vg0/backups 
         
         
 ---Chúng tôi sẽ sử dụng file system ext4 vì nó cho phép chúng ta tăng và giảm kích thước của mỗi logical volume (với file system xfs chỉ cho phép tăng kích thước). Chúng ta thực hiện như sau:
 
 câu lệnh: mkfs.ext4 /dev/vg0/projects 
          : mkfs.ext4 /dev/vg0/backups 
          
          
2.2. Mở rộng Volume Group và thay đổi kích thước các Logical Volume

---Trong ví dụ dưới đây chúng ta sẽ thêm một physical volume có tên /dev/sdd với kích thước 10GB vào volume group vg0, sau đó chúng ta sẽ tăng kích thước của logical volume /projects lên 10GB thực hiện như sau:

---Chạy các lệnh sau để tạo điểm gắn kết:   mkdir /projecs   và mkdir /backups


---Chạy lệnh sau để mount:
+ mount /dev/vg0/projects /projects 
+ mount /dev/vg0/backups  /backups 


---Chạy lệnh sau kiểm tra sử dụng không gian đĩa hệ thống tập tin:
+ df -TH

----Sử dụng lệnh sau để thêm /dev/sdd vào volume group vg0:

+ vgextend vg0 /dev/sdd 

---Chúng ta chạy lệnh vgdisplay vg0 trước và sau khi thực hiện lệnh vgextend vg0 /dev/sdd, bạn sẽ thấy sự tăng kích thước của volume group(VG):

+  chạy câu lệnh: vgdisplay vg0 trước và sau lệnh vgextend vg0 /dev/sdd 


---Qua lệnh kiểm tra trên chúng ta thấy dung lượng thêm vào của chúng ta là 10GB chúng ta có thể tăng kích thước của logical volume /projects lên 10GB thực hiện như sau:  

+ câu lệnh: lvextend -l +2000 /dev/vg0/projects 

--Sau khi chạy lệnh trên chúng ta cần thay đổi kích thước hệ thống tệp, vì thế chúng ta phải chạy lệnh sau để resize: 

+Đối với file system (ext2, ext3, ext 4): resize2fs.

+Đối với file system (xfs): xfs_growfs. 

+ câu lệnh: resize2fs /dev/vg0/projects 
+ câu lệnh: df -TH --- để kiểm tra lại  


2.3. Giảm kích cỡ Logical Volume

---Khi chúng ta muốn giảm dung lượng các Logical Volume. Chúng ta cần phải chú ý vì nó rất quan trọng và có thể bị lỗi trong khi chúng ta giảm dung lượng Logical Volume. Để đảm bảo an toàn khi giảm Logical Volume cần thực hiện các bước sau:

    Trước khi bắt đầu, cần sao lưu dữ liệu vì vậy sẽ không phải đau đầu nếu có sự cố xảy ra.
    Để giảm dung lượng Logical Volume, cần thực hiện đầy đủ và cẩn thận 5 bước cần thiết.
    Khi giảm dung lượng Logical Volume chúng ta phải ngắt kết nối hệ thống tệp trước khi giảm.

Cần thực hiện cẩn thận 5 bước dưới đây:

    Ngắt kết nối file system.
    Kiểm tra file system sau khi ngắt kết nối.
    Giảm file system.
    Giảm kích thước Logical Volume hơn kích thước hiện tại.
    Kiểm tra lỗi cho file system.
    Mount lại file system và kiểm tra kích thước của nó.


---Ví dụ: Giảm Logical Volume có tên project với kích thước từ 17.81GB giảm xuống còn 10GB mà không làm mất dữ liệu. Chúng ta thực hiện các bước như sau:

Kiểm tra dung lượng của Logical Volume và kiểm tra file system trước khi thực hiện giảm:

câu lệnh: lvs
 	: df -TH   --- để xem
 	
Bước 1: Umount file system 

Sử dụng lệnh umount:

+ câu lệnh: umount /projects/ 
+ câu lệnh: df -TH 

Bước 2: Kiểm tra lỗi file system bằng lệnh e2fsck.

+câu lệnh: e2fsck -f /dev/vg0/projects
Trong đó tùy chọn -f dùng để kiểm tra(force check). 

Bước 3: Giảm kích thước của projects theo kích thước mong muốn.

Giảm Logical Volume có tên projects với kích thước từ 17.81GB giảm xuống còn 10GB chúng ta thực hiện như sau:

+câu lệnh: resize2fs /dev/vg0/projects 10G 

Bước 4: Bây giờ giảm kích thước bằng lệnh lvreduce.

+ câu lệnh: lvreduce -L 10G /dev/vg0/projects

Bước 5: Để đảm bảo an toàn, bây giờ kiểm tra lỗi file system đã giảm


+ câu lệnh: e2fsck -f /dev/vg0/projects 
 
Bước 6: Gắn kết file system và kiểm tra kích thước của nó.

+ câu lệnh: mount /dev/vg0/projects /projects/
+ câu lệnh: lvs


2.4. Mounting Logical Volume

---Chúng ta cần phải gắn kết vĩnh viễn. Để thực hiện gắn kết vĩnh viễn phải nhập trong tệp /etc/fstab. Bạn có thể sử dụng trình soạn thảo vi để nhập vào:

+ câu lệnh: vi /etc/fstab 

* ví dụ:#
# /etc/fstab
# Created by anaconda on Thu Apr 11 21:36:46 2019
#
# Accessible filesystems, by reference, are maintained under '/dev/disk'
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
#
/dev/mapper/cl-root     /                       xfs     defaults        0 0
UUID=8c1d2c4f-13d0-4ec9-ae3d-f706311400ad /boot                   xfs     defaults        0 0

UUID=3fe80222-0f42-4d34-8ce7-e4f51c3a7f61 /backups ext4 defaults 0 0
UUID=314f59be-2c3c-4ded-bc3e-cd79544ef1ee /projects ext4 defaults 0 0 
--hết ví dụ-- 

---Để xác định UUID trên mỗi đĩa. Chúng ta chạy lệnh sau:

+ câu lệnh: blkid /dev/vg0/projects
+ câu lệnh: blkid /dev/vg0/backups 

-- Khi đã biết UUID và hệ thống tệp, chúng tôi có thể nhập vào tệp /etc/fstab. Các tập tin fstab có định dạng sau.
+[Device] [Mount Point] [File System Type] [Options] [Dump] [Pass] 

--Lưu lại file /etc/fstab và chạy lệnh sau lưu các thay đổi và gắn kết LV:
+ câu lệnh: mount -a
+ câu lệnh: mount | grep backups
+ câu lệnh: mount | grep projects 

--Nếu có lỗi, không reboot server để tránh tình trạng server không thể khởi động. Kiểm tra cấu hình trong file /etc/fstab và chạy lại lệnh cho tới khi không có thông báo lỗi.



3. Snapshot và restore của Logical Volume
3.1. Snapshot Logical Volume
3.1.1. Tạo snapshot LVM

--Trước khi tạo snapshot thì chúng ta kiểm tra dev/vg0/projects:
+câu lệnh: cd /projects/ 
+ câu lệnh: ls -l


--Kiểm tra không gian trống trong volume groupg để tạo snapshot mới chúng ta thực hiện như sau:

+ câu lệnh: vgs
+ câu lệnh: lvs 

--Qua lệnh kiểm tra trên chúng ta thấy hiện có 2.18GB dung lượng trống còn lại. Vì vậy, tạo một snapshot có tên là snapshot_1 với dung lượng 1GB bằng các lệnh sau:

+ câu lệnh: lvcreate -L 1GB -s -n snapshot_1 /dev/vg0/projects 

--Trong đó ý nghĩa các tuỳ chọn là:

    -s: Tạo snapshot
    -n: Tên cho snapshot

Tương tự chúng ta tạo một snapshot có tên là snapshot_2 với dung lượng 1GB.

Nếu bạn muốn snapshot, bạn có thể sử dụng lệnh lvremove.

+ câu lệnh: lvremove /dev/vg0/snapshot_2 

--Kiểm tra lại snapshot đã được tạo, chúng ta thực hiện như bên dưới:
+ câu : lvs 


--Chúng ta sẽ thêm một số tệp mới vào /dev/vg0/projects với dung lượng tệp khoảng 719MB và kích thước snapshot của chúng ta là 1GB. Vì vậy, có đủ không gian để sao lưu các thay đổi của chúng ta. Chúng ta thực hiện lệnh bên dưới để kiểm tra:
+ câu lệnh: lvs 

--Qua việc kiểm tra trên chúng ta thấy 68.30% dung lượng snapshot đã được sử dụng. Để biết thêm thông tin chi tiết chúng ta sử dụng lệnh sau:

+ câu lệnh: lvdisplay /dev/vg0/snapshot_1 


--trong đó ý nghĩa các trường của lệnh lvdisplay như sau:

    LV Name: Tên của Snapshot Logical Volume.
    VG Name.: Tên Volume group đang được sử dụng.
    LV Write Access: Snapshot volume ở chế độ đọc và ghi.
    LV Creation host, time: Thời gian khi snapshot được tạo. Nó rất quan trọng vì snapshot sẽ tìm mọi thay đổi sau thời gian này.
    LV snapshot status: Snapshot này thuộc vào logical volume projects.
    LV Size: Kích thước của Source volume mà bạn đã snapshot.
    COW-table size: Kích thước bảng Cow.
    Snapshot chunk size: Cung cấp kích thước của chunk cho snapshot.    
    
 ---Chúng ta tiếp tục sao chép tệp có dung lượng lớn hơn 1GB vào /dev/vg0/projects và bạn sẽ nhận được thông báo lỗi "Input/output error" điều đó có nghĩa là hết dung lượng trong snapshot.
    
  /dev/vg0/snapshot_1: read failed after 0 of 4096 at 10737355714: Input/output error
  /dev/vg0/snapshot_1: read failed after 0 of 4096 at 10737412422: Input/output error
  /dev/vg0/snapshot_1: read failed after 0 of 4096 at 0: Input/output error
  /dev/vg0/snapshot_1: read failed after 0 of 4096 at 4096: Input/output error
  LV          VG  Attr       LSize  Pool Origin   Data%  Meta%  Move Log Cpy%Sync Convert
  root        cl  -wi-ao---- 17.00g
  swap        cl  -wi-ao----  2.00g
  backups     vg0 -wi-ao----  9.99g
  projects    vg0 owi-aos--- 17.81g
  snapshot_1 vg0 swi-I-s---  1.00g      projects 100.00

Nếu chúng ta có Source volume có kích thước là 10GB thì chúng ta cũng nên tạo snapshot có dung lượng 10GB để đủ không gian chứa các thay đổi của Source volume.

    Chú ý: Dung lượng Snapshot tăng lên đúng bằng dung lượng tạo mới trên LV. Không thể tạo Snapshot mới ghi đè lên Snapshot cũ. Trường hợp bạn có 2 Snapshot cho cùng 1 ổ LV thì dữ liệu mới cũng được ghi cả vào 2 ổ Snapshot. 
    
    
    Bài viết này giới thiệu với các bạn cách tạo và quản lý LVM trong hệ điều hành Linux giúp các bạn có thể tự học Linux dễ dàng.
1. Logical Volume Management

Logical Volume Management (LVM) đã có sẵn trên hầu hết trên các bản phân phối Linux, có nhiều lợi thế so với quản lý phân vùng truyền thống. Logical Volume Management được sử dụng để tạo nhiều ổ đĩa logic. Nó cho phép các bộ phận logic được thay đổi kích thước (giảm hoặc tăng) theo ý muốn của người quản trị.

Cấu trúc của LVM bao gồm:

    Một hoặc nhiều đĩa cứng hoặc phân vùng được định cấu hình là physical volume(PV).
    Một volume group(VG) được tạo bằng cách sử dụng một hoặc nhiều khối vật lý.
    Nhiều logical volume có thể được tạo trong một volume group.

2. Các bước để quản lý và tạo LVM bằng các lệnh vgcreate, lvcreate và lvextend
2.1. Tạo Physical Volume, Volume Group, và Logical Volume
2.1.1. Tạo Physical Volume

Chạy lệnh sau để tạo physical volume(PV) trên /dev/sdb, /dev/sdc, và /dev/sdd

[root@localhost ~]# pvcreate /dev/sdb /dev/sdc /dev/sdd
  Physical volume "/dev/sdb" successfully created.
  Physical volume "/dev/sdc" successfully created.
  Physical volume "/dev/sdd" successfully created.

Để liệt kê các physical volume(PV) mới được tạo, chạy như sau:

[root@localhost ~]# pvs
  PV         VG Fmt  Attr PSize   PFree
  /dev/sda2  cl lvm2 a--  <19.00g     0
  /dev/sdb      lvm2 ---   10.00g 10.00g
  /dev/sdc      lvm2 ---   10.00g 10.00g
  /dev/sdd      lvm2 ---   10.00g 10.00g

Ý nghĩa các trường của pvs:

    PV: Đĩa được sử dụng
    PFree: Kích thước đĩa vật lý (Kích thước PV)

Để có được thông tin chi tiết về mỗi physical volume(PV), sử dụng lệnh sau: pvdisplay

Xem thông tin chi tiết về physical volume(PV) /dev/sdb. Chúng ta thực hiện như sau:

[root@localhost ~]# pvdisplay /dev/sdb
  "/dev/sdb" is a new physical volume of "10.00 GiB"
  --- NEW Physical volume ---
  PV Name               /dev/sdb
  VG Name
  PV Size               10.00 GiB
  Allocatable           NO
  PE Size               0
  Total PE              0
  Free PE               0
  Allocated PE          0
  PV UUID               sprsx7-glR2-P7w3-40FG-Fzey-ad57-VTGhA2

Tương tự cho /dev/sdc và /dev/sdd:

[root@localhost ~]# pvdisplay /dev/sdc
  "/dev/sdc" is a new physical volume of "10.00 GiB"
  --- NEW Physical volume ---
  PV Name               /dev/sdc
  VG Name
  PV Size               10.00 GiB
  Allocatable           NO
  PE Size               0
  Total PE              0
  Free PE               0
  Allocated PE          0
  PV UUID               HBbxa9-pepX-Dr5z-B4fJ-lTSb-JcfV-me7Wwo
[root@localhost ~]# pvdisplay /dev/sdd
  "/dev/sdd" is a new physical volume of "10.00 GiB"
  --- NEW Physical volume ---
  PV Name               /dev/sdd
  VG Name
  PV Size               10.00 GiB
  Allocatable           NO
  PE Size               0
  Total PE              0
  Free PE               0
  Allocated PE          0
  PV UUID               7cGgRT-DVBS-Kz0x-LIiB-qzN8-bvxl-HYxKdl

    Lưu ý: Nếu chúng ta có 2 ổ đĩa hay nhiều ổ đĩa để tạo một volume mà một đĩa ở volume bị mất thì dẫn tới volume đó mất luôn, vì thế phải chạy LVM trên RAID hoặc dùng tính năng RAID của LVM để có khả năng dung lỗi.

2.1.2. Tạo Volume Group

Để tạo volume group với tên vg0 bằng cách sử dụng /dev/sdb và /dev/sdc. Chúng ta thực hiện như sau:

[root@localhost ~]# vgcreate vg0 /dev/sdb /dev/sdc
  Volume group "vg0" successfully created

Thực hiện lệnh sau để xem thông tin volume group vừa tạo:

[root@localhost ~]# vgdisplay vg0
  --- Volume group ---
  VG Name               vg0
  System ID
  Format                lvm2
  Metadata Areas        2
  Metadata Sequence No  1
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                2
  Act PV                2
  VG Size               19.99 GiB
  PE Size               4.00 MiB
  Total PE              5118
  Alloc PE / Size       0 / 0
  Free  PE / Size       5118 / 19.99 GiB
  VG UUID               3M10Re-sNdU-3UGY-h4WO-IXV1-pOW7-NUBOBC

Vì vg0 chứa hai đĩa 10GB nên VG Size = 19.99GB

Ý nghĩa các thông tin của Volume group khi chạy lệnh vgdisplay:

    VG Name: Tên Volume Group.
    Format: Kiến trúc LVM được sử dụng.
    VG Access: Volume Group có thể đọc và viết và sẵn sàng để sử dụng.
    VG Status: Volume Group có thể được định cỡ lại, chúng ta có thể mở rộng thêm nếu cần thêm dung lượng.
    PE Size: Mở rộng Physical, Kích thước cho đĩa có thể được xác định bằng kích thước PE hoặc GB, 4MB là kích thước PE mặc định của LVM
    Total PE: Dung lượng Volume Group có
    Alloc PE: Tổng PE đã sử dụng
    Free PE: Tổng PE chưa được sử dụng

Chúng ta có thể kiểm tra số lượng physical volume(PV) dùng để tạo volume group như sau:

[root@localhost ~]# vgs
  VG   #PV #LV #SN Attr   VSize   VFree
  cl     1   2   0 wz--n- <19.00g     0
  vg0   2   0   0 wz--n-  19.99g 19.99g

Trong đó:

    VG: Tên Volume Group
    #PV: Physical Volume sử dụng trong Volume Group
    VFree: Hiển thị không gian trống có sẵn trong Volume Group
    VSize: Tổng kích thước của Volume Group
    #LV: Logical Volume nằm trong volume group
    #SN: Số lượng Snapshot của volume group
    Attr: Trạng thái của Volume group có thể ghi, có thể đọc, có thể thay đổi,

Khi tạo ra các logical volume, chúng ta cần phải xem xét dung lượng khi tạo logical volume sau cho phù hợp với nhu cầu sử dụng.
2.1.3. Tạo Logical Volume

Chúng ta sẽ tạo 2 logical volume với tên projects có dung lượng là 10GB và backups sử dụng toàn bộ dung lượng còn lại của volume group. Chúng ta chạy lệnh sau:

[root@localhost ~]# lvcreate -n projects -L 10G vg0
  Logical volume "projects" created.
[root@localhost ~]# lvcreate -n backups -l 100%FREE vg0
  Logical volume "backups" created.

Trong đó:

    -n: Sử dụng chỉ ra tên của logical volume cần tạo.
    -L: Sử dụng chỉ một kích thước cố định.
    -l: Sử dụng chỉ phần trăm của không gian còn lại trong volume group.

Chạy lệnh sau để xem danh sách logical volume vừa được tạo:

[root@localhost ~]# lvs
  LV           VG   Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  root         cl   -wi-ao---- <17.00g
  swap         cl   -wi-a-----   2.00g
  backups      vg0  -wi-a-----   9.99g
  projects     vg0  -wi-a-----  10.00g

Ý nghĩa các trường của lvs:

    LV: Tên logical volume
    %Data: Phần trăm dung lượng logical volume được sử dụng
    Lsize: Kích thước của logical volume

Sử dụng lệnh sau để hiển thị thông tin chi tiết của các logical volume:

[root@localhost ~]# lvdisplay vg0/projects
  --- Logical volume ---
  LV Path                /dev/vg0/projects
  LV Name                projects
  VG Name                vg0
  LV UUID                zGbCrQ-FyrO-EjPu-cE5N-7JmQ-ECxt-kJuuFJ
  LV Write Access        read/write
  LV Creation host, time localhost.localdomain, 2019-04-14 20:14:30 +0700
  LV Status              available
  # open                 0
  LV Size                10.00 GiB
  Current LE             2560
  Segments               2
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:2

[root@localhost ~]# lvdisplay vg0/backups
  --- Logical volume ---
  LV Path                /dev/vg0/backups
  LV Name                backups
  VG Name                vg0
  LV UUID                Hdk7t7-OyYj-q5gn-kNla-1cM5-rDCH-6FCmph
  LV Write Access        read/write
  LV Creation host, time localhost.localdomain, 2019-04-14 20:14:41 +0700
  LV Status              available
  # open                 0
  LV Size                9.99 GiB
  Current LE             2558
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:3

Chúng tôi sẽ sử dụng file system ext4 vì nó cho phép chúng ta tăng và giảm kích thước của mỗi logical volume (với file system xfs chỉ cho phép tăng kích thước). Chúng ta thực hiện như sau:

[root@localhost ~]# mkfs.ext4 /dev/vg0/projects
mke2fs 1.42.9 (28-Dec-2013)
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
Stride=0 blocks, Stripe width=0 blocks
655360 inodes, 2621440 blocks
131072 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=2151677952
80 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks:
	32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632

Allocating group tables: done
Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

[root@localhost ~]# mkfs.ext4 /dev/vg0/backups
mke2fs 1.42.9 (28-Dec-2013)
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
Stride=0 blocks, Stripe width=0 blocks
655360 inodes, 2619392 blocks
130969 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=2151677952
80 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks:
	32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632

Allocating group tables: done
Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done

2.2. Mở rộng Volume Group và thay đổi kích thước các Logical Volume

Trong ví dụ dưới đây chúng ta sẽ thêm một physical volume có tên /dev/sdd với kích thước 10GB vào volume group vg0, sau đó chúng ta sẽ tăng kích thước của logical volume /projects lên 10GB thực hiện như sau:

Chạy các lệnh sau để tạo điểm gắn kết:

[root@localhost ~]# mkdir /projects
[root@localhost ~]# mkdir /backups

Chạy lệnh sau để mount:

[root@localhost ~]# mount /dev/vg0/projects /projects/
[root@localhost ~]# mount /dev/vg0/backups /backups/

Chạy lệnh sau kiểm tra sử dụng không gian đĩa hệ thống tập tin:

[root@localhost ~]# df -TH
Filesystem               Type      Size  Used Avail Use% Mounted on
/dev/mapper/cl-root      xfs        19G  1.1G   18G   6% /
devtmpfs                 devtmpfs  501M     0  501M   0% /dev
tmpfs                    tmpfs     512M     0  512M   0% /dev/shm
tmpfs                    tmpfs     512M  7.1M  505M   2% /run
tmpfs                    tmpfs     512M     0  512M   0% /sys/fs/cgroup
/dev/sda1                xfs       1.1G  145M  919M  14% /boot
tmpfs                    tmpfs     103M     0  103M   0% /run/user/0
/dev/mapper/vg0-projects ext4      11G   38M   9.9G   1% /projects
/dev/mapper/vg0-backups  ext4      11G   38M   9.9G   1% /backups

Sử dụng lệnh sau để thêm /dev/sdd vào volume group vg0:

[root@localhost ~]# vgextend vg0 /dev/sdd
  Volume group "vg0" successfully extended

Chúng ta chạy lệnh vgdisplay vg0 trước và sau khi thực hiện lệnh vgextend vg0 /dev/sdd, bạn sẽ thấy sự tăng kích thước của volume group(VG):

Trước khi chạy lệnh vgextend vg0 /dev/sdd

[root@localhost ~]# vgdisplay vg0
  --- Volume group ---
  VG Name               vg0
  System ID
  Format                lvm2
  Metadata Areas        2
  Metadata Sequence No  3
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                2
  Open LV               2
  Max PV                0
  Cur PV                2
  Act PV                2
  VG Size               19.99 GiB
  PE Size               4.00 MiB
  Total PE              5118
  Alloc PE / Size       5118 / 19.99 GiB
  Free  PE / Size       0 / 0
  VG UUID               3M10Re-sNdU-3UGY-h4WO-IXV1-pOW7-NUBOBC

Sau khi chạy lệnh vgextend vg0 /dev/sdd

[root@localhost ~]# vgdisplay vg0
  --- Volume group ---
  VG Name               vg0
  System ID
  Format                lvm2
  Metadata Areas        3
  Metadata Sequence No  6
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                2
  Open LV               0
  Max PV                0
  Cur PV                3
  Act PV                3
  VG Size               <29.99 GiB
  PE Size               4.00 MiB
  Total PE              7677
  Alloc PE / Size       5118 / 19.99 GiB
  Free  PE / Size       2559 / <10.00 GiB
  VG UUID               3M10Re-sNdU-3UGY-h4WO-IXV1-pOW7-NUBOBC

Qua lệnh kiểm tra trên chúng ta thấy dung lượng thêm vào của chúng ta là 10GB chúng ta có thể tăng kích thước của logical volume /projects lên 10GB thực hiện như sau:

[root@localhost ~]# lvextend -l +2000 /dev/vg0/projects
  Size of logical volume vg0/projects changed from 10.00 GiB (1920 extents) to 17.81 GiB (4560 extents).
  Logical volume vg0/projects successfully resized.

Sau khi chạy lệnh trên chúng ta cần thay đổi kích thước hệ thống tệp, vì thế chúng ta phải chạy lệnh sau để resize:

    Đối với file system (ext2, ext3, ext 4): resize2fs.

    Đối với file system (xfs): xfs_growfs.

    [root@localhost ~]# resize2fs /dev/vg0/projects
    resize2fs 1.42.9 (28-Dec-2013)
    Filesystem at /dev/vg0/projects is mounted on /projects; on-line resizing required
    old_desc_blocks = 1, new_desc_blocks = 2
    The filesystem on /dev/vg0/projects is now 4669440 blocks long.

    [root@localhost ~]# df -TH
    Filesystem               Type      Size  Used Avail Use% Mounted on
    /dev/mapper/cl-root      xfs        19G  1.1G   18G   6% /
    devtmpfs                 devtmpfs  501M     0  501M   0% /dev
    tmpfs                    tmpfs     512M     0  512M   0% /dev/shm
    tmpfs                    tmpfs     512M  7.1M  505M   2% /run
    tmpfs                    tmpfs     512M     0  512M   0% /sys/fs/cgroup
    /dev/sda1                xfs       1.1G  145M  919M  14% /boot
    tmpfs                    tmpfs     103M     0  103M   0% /run/user/0
    /dev/mapper/vg0-projects ext4       19G   47M   18G   1% /projects
    /dev/mapper/vg0-backups   ext4       11G   38M  9.9G   1% /backups

2.3. Giảm kích cỡ Logical Volume

Khi chúng ta muốn giảm dung lượng các Logical Volume. Chúng ta cần phải chú ý vì nó rất quan trọng và có thể bị lỗi trong khi chúng ta giảm dung lượng Logical Volume. Để đảm bảo an toàn khi giảm Logical Volume cần thực hiện các bước sau:

    Trước khi bắt đầu, cần sao lưu dữ liệu vì vậy sẽ không phải đau đầu nếu có sự cố xảy ra.
    Để giảm dung lượng Logical Volume, cần thực hiện đầy đủ và cẩn thận 5 bước cần thiết.
    Khi giảm dung lượng Logical Volume chúng ta phải ngắt kết nối hệ thống tệp trước khi giảm.

Cần thực hiện cẩn thận 5 bước dưới đây:

    Ngắt kết nối file system.
    Kiểm tra file system sau khi ngắt kết nối.
    Giảm file system.
    Giảm kích thước Logical Volume hơn kích thước hiện tại.
    Kiểm tra lỗi cho file system.
    Mount lại file system và kiểm tra kích thước của nó.

Ví dụ: Giảm Logical Volume có tên project với kích thước từ 17.81GB giảm xuống còn 10GB mà không làm mất dữ liệu. Chúng ta thực hiện các bước như sau:

Kiểm tra dung lượng của Logical Volume và kiểm tra file system trước khi thực hiện giảm:

[root@localhost ~]# lvs
  LV       VG  Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  root     cl  -wi-ao---- 17.00g
  swap     cl  -wi-ao----  2.00g
  backups  vg0 -wi-ao---- 10.00g
  projects vg0 -wi-ao---- 17.81g
[root@localhost ~]# df -TH
Filesystem               Type      Size  Used Avail Use% Mounted on
/dev/mapper/cl-root      xfs        19G  6.8G   12G  37% /
devtmpfs                 devtmpfs  501M     0  501M   0% /dev
tmpfs                    tmpfs     512M     0  512M   0% /dev/shm
tmpfs                    tmpfs     512M  7.1M  505M   2% /run
tmpfs                    tmpfs     512M     0  512M   0% /sys/fs/cgroup
/dev/sda1                xfs       1.1G  145M  919M  14% /boot
tmpfs                    tmpfs     103M     0  103M   0% /run/user/0
/dev/mapper/vg0-projects ext4       19G  4.4G   14G  25% /projects
/dev/mapper/vg0-backups  ext4       11G  4.4G  5.6G  44% /backups

Bước 1: Umount file system

Sử dụng lệnh umount bên dưới:

[root@localhost ~]# umount /projects/
[root@localhost ~]# df -TH
Filesystem              Type      Size  Used Avail Use% Mounted on
/dev/mapper/cl-root     xfs        19G  6.8G   12G  37% /
devtmpfs                devtmpfs  501M     0  501M   0% /dev
tmpfs                   tmpfs     512M     0  512M   0% /dev/shm
tmpfs                   tmpfs     512M  7.1M  505M   2% /run
tmpfs                   tmpfs     512M     0  512M   0% /sys/fs/cgroup
/dev/sda1               xfs       1.1G  145M  919M  14% /boot
tmpfs                   tmpfs     103M     0  103M   0% /run/user/0
/dev/mapper/vg0-backups ext4       11G  4.4G  5.6G  44% /backups

Bước 2: Kiểm tra lỗi file system bằng lệnh e2fsck.

[root@localhost ~]# e2fsck -f /dev/vg0/projects
e2fsck 1.42.9 (28-Dec-2013)
Pass 1: Checking inodes, blocks, and sizes
Pass 2: Checking directory structure
Pass 3: Checking directory connectivity
Pass 4: Checking reference counts
Pass 5: Checking group summary information
/dev/vg0/projects: 11/1171456 files (0.0% non-contiguous), 117573/4669440 blocks

Trong đó tùy chọn -f dùng để kiểm tra(force check).

Bước 3: Giảm kích thước của projects theo kích thước mong muốn.

Giảm Logical Volume có tên projects với kích thước từ 17.81GB giảm xuống còn 10GB chúng ta thực hiện như sau:

[root@localhost ~]# resize2fs /dev/vg0/projects 10G
resize2fs 1.42.9 (28-Dec-2013)
Resizing the filesystem on /dev/vg0/projects to 2621440 (4k) blocks.
The filesystem on /dev/vg0/projects is now 2621440 blocks long.

Bước 4: Bây giờ giảm kích thước bằng lệnh lvreduce.

[root@localhost ~]# lvreduce -L 10G /dev/vg0/projects
  WARNING: Reducing active logical volume to 10.00 GiB.
  THIS MAY DESTROY YOUR DATA (filesystem etc.)
Do you really want to reduce vg0/projects? [y/n]: y
  Size of logical volume vg0/projects changed from 17.81 GiB (4560 extents) to 10.00 GiB (2560 extents).
  Logical volume vg0/projects successfully resized.

Bước 5: Để đảm bảo an toàn, bây giờ kiểm tra lỗi file system đã giảm

[root@localhost ~]# e2fsck -f /dev/vg0/projects
e2fsck 1.42.9 (28-Dec-2013)
Pass 1: Checking inodes, blocks, and sizes
Pass 2: Checking directory structure
Pass 3: Checking directory connectivity
Pass 4: Checking reference counts
Pass 5: Checking group summary information
/dev/vg0/projects: 11/655360 files (0.0% non-contiguous), 83137/2621440 blocks

Bước 6: Gắn kết file system và kiểm tra kích thước của nó.

[root@localhost ~]# mount /dev/vg0/projects /projects/
[root@localhost ~]# lvs
  LV       VG  Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  root     cl  -wi-ao---- 17.00g
  swap     cl  -wi-ao----  2.00g
  backups  vg0 -wi-ao---- 10.00g
  projects vg0 -wi-ao---- 10.00g
[root@localhost ~]# df -TH
Filesystem               Type      Size  Used Avail Use% Mounted on
/dev/mapper/cl-root      xfs        19G  6.8G   12G  37% /
devtmpfs                 devtmpfs  501M     0  501M   0% /dev
tmpfs                    tmpfs     512M     0  512M   0% /dev/shm
tmpfs                    tmpfs     512M  7.1M  505M   2% /run
tmpfs                    tmpfs     512M     0  512M   0% /sys/fs/cgroup
/dev/sda1                xfs       1.1G  145M  919M  14% /boot
tmpfs                    tmpfs     103M     0  103M   0% /run/user/0
/dev/mapper/vg0-backups  ext4       11G  4.4G  5.6G  44% /backups
/dev/mapper/vg0-projects ext4       11G  4.4G  5.6G  44% /projects

2.4. Mounting Logical Volume

Chúng ta cần phải gắn kết vĩnh viễn. Để thực hiện gắn kết vĩnh viễn phải nhập trong tệp /etc/fstab. Bạn có thể sử dụng trình soạn thảo vi để nhập vào:

[root@localhost ~]# vi /etc/fstab

#
# /etc/fstab
# Created by anaconda on Thu Apr 11 21:36:46 2019
#
# Accessible filesystems, by reference, are maintained under '/dev/disk'
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
#
/dev/mapper/cl-root     /                       xfs     defaults        0 0
UUID=8c1d2c4f-13d0-4ec9-ae3d-f706311400ad /boot                   xfs     defaults        0 0

UUID=3fe80222-0f42-4d34-8ce7-e4f51c3a7f61 /backups ext4 defaults 0 0
UUID=314f59be-2c3c-4ded-bc3e-cd79544ef1ee /projects ext4 defaults 0 0

Để xác định UUID trên mỗi đĩa. Chúng ta chạy lệnh sau:

[root@localhost ~]# blkid /dev/vg0/projects
/dev/vg0/projects: UUID="314f59be-2c3c-4ded-bc3e-cd79544ef1ee" TYPE="ext4"
[root@localhost ~]# blkid /dev/vg0/backups
/dev/vg0/backups: UUID="3fe80222-0f42-4d34-8ce7-e4f51c3a7f61" TYPE="ext4"

Khi đã biết UUID và hệ thống tệp, chúng tôi có thể nhập vào tệp /etc/fstab. Các tập tin fstab có định dạng sau.

[Device] [Mount Point] [File System Type] [Options] [Dump] [Pass]

Lưu lại file /etc/fstab và chạy lệnh sau lưu các thay đổi và gắn kết LV:

[root@localhost ~]# mount -a
[root@localhost ~]# mount | grep backups
/dev/mapper/vg0-backups on /backups type ext4 (rw,relatime,seclabel,data=ordered)
[root@localhost ~]# mount | grep projects
/dev/mapper/vg0-projects on /projects type ext4 (rw,relatime,seclabel,data=ordered)

Nếu có lỗi, không reboot server để tránh tình trạng server không thể khởi động. Kiểm tra cấu hình trong file /etc/fstab và chạy lại lệnh cho tới khi không có thông báo lỗi.
3. Snapshot và restore của Logical Volume
3.1. Snapshot Logical Volume
3.1.1. Tạo snapshot LVM

Trước khi tạo snapshot thì chúng ta kiểm tra dev/vg0/projects:

[root@localhost ~]# cd /projects/
[root@localhost projects]# ls -l
total 417812
-rw-r--r--. 1 root root 427819008 Apr 28 12:11 CentOS-6.9-x86_64-minimal.iso
drwx------. 2 root root     16384 Apr 28 12:02 lost+found
-rw-r--r--. 1 root root        12 Apr 28 12:20 test1.txt
[root@localhost projects]# cat test1.txt
Hello Blogd

Kiểm tra không gian trống trong volume groupg để tạo snapshot mới chúng ta thực hiện như sau:

[root@localhost ~]# vgs
  VG  #PV #LV #SN Attr   VSize  VFree
  cl    1   2   0 wz--n- 19.00g    0
  vg0   3   2   0 wz--n- 29.99g 2.18g
[root@localhost ~]# lvs
  LV        VG  Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  root      cl  -wi-ao---- 17.00g
  swap      cl  -wi-ao----  2.00g
  backups   vg0 -wi-ao----  9.99g
  projects vg0 -wi-ao---- 17.81g

Qua lệnh kiểm tra trên chúng ta thấy hiện có 2.18GB dung lượng trống còn lại. Vì vậy, tạo một snapshot có tên là snapshot_1 với dung lượng 1GB bằng các lệnh sau:

[root@localhost ~]# lvcreate -L 1GB -s -n snapshot_1 /dev/vg0/projects
  Using default stripesize 64.00 KiB.
  Logical volume "snapshot_1" created.

Trong đó ý nghĩa các tuỳ chọn là:

    -s: Tạo snapshot
    -n: Tên cho snapshot

Tương tự chúng ta tạo một snapshot có tên là snapshot_2 với dung lượng 1GB.

Nếu bạn muốn snapshot, bạn có thể sử dụng lệnh lvremove.

[root@localhost ~]# lvremove /dev/vg0/snapshot_2
Do you really want to remove active logical volume vg0/snapshot_2? [y/n]: y
  Logical volume "snapshot_2" successfully removed

Kiểm tra lại snapshot đã được tạo, chúng ta thực hiện như bên dưới:

[root@localhost ~]# lvs
  LV          VG  Attr       LSize  Pool Origin    Data%  Meta%  Move Log Cpy%Sync Convert
  root        cl  -wi-ao---- 17.00g
  swap        cl  -wi-ao----  2.00g
  backups     vg0 -wi-ao----  9.99g
  projects   vg0 owi-aos--- 17.81g
  snapshot_1 vg0 swi-a-s---  1.00g      projiects 0.00

Chúng ta sẽ thêm một số tệp mới vào /dev/vg0/projects với dung lượng tệp khoảng 719MB và kích thước snapshot của chúng ta là 1GB. Vì vậy, có đủ không gian để sao lưu các thay đổi của chúng ta. Chúng ta thực hiện lệnh bên dưới để kiểm tra:

[root@localhost ~]# lvs
  LV          VG  Attr       LSize  Pool Origin   Data%  Meta%  Move Log Cpy%Sync Convert
  root        cl  -wi-ao---- 17.00g
  swap        cl  -wi-ao----  2.00g
  backups     vg0 -wi-ao----  9.99g
  projects    vg0 owi-aos--- 17.81g
  snapshot_1 vg0 swi-a-s---  1.00g      projects 68.30

Qua việc kiểm tra trên chúng ta thấy 68.30% dung lượng snapshot đã được sử dụng. Để biết thêm thông tin chi tiết chúng ta sử dụng lệnh sau:

[root@localhost ~]# lvdisplay /dev/vg0/snapshot_1
  --- Logical volume ---
  LV Path                /dev/vg0/snapshot_1
  LV Name                snapshot_1
  VG Name                vg0
  LV UUID                se3aTX-JKSc-yaIZ-ht55-jIrF-w4Hc-Uy9WXd
  LV Write Access        read/write
  LV Creation host, time localhost.localdomain, 2019-04-21 07:23:46 +0700
  LV snapshot status     INACTIVE destination for projects
  LV Status              available
  # open                 0
  LV Size                17.81 GiB
  Current LE             4560
  COW-table size         1.00 GiB
  COW-table LE           384
  Snapshot chunk size    4.00 KiB
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:6

Trong đó ý nghĩa các trường của lệnh lvdisplay như sau:

    LV Name: Tên của Snapshot Logical Volume.
    VG Name.: Tên Volume group đang được sử dụng.
    LV Write Access: Snapshot volume ở chế độ đọc và ghi.
    LV Creation host, time: Thời gian khi snapshot được tạo. Nó rất quan trọng vì snapshot sẽ tìm mọi thay đổi sau thời gian này.
    LV snapshot status: Snapshot này thuộc vào logical volume projects.
    LV Size: Kích thước của Source volume mà bạn đã snapshot.
    COW-table size: Kích thước bảng Cow.
    Snapshot chunk size: Cung cấp kích thước của chunk cho snapshot.

Chúng ta tiếp tục sao chép tệp có dung lượng lớn hơn 1GB vào /dev/vg0/projects và bạn sẽ nhận được thông báo lỗi "Input/output error" điều đó có nghĩa là hết dung lượng trong snapshot.

  /dev/vg0/snapshot_1: read failed after 0 of 4096 at 10737355714: Input/output error
  /dev/vg0/snapshot_1: read failed after 0 of 4096 at 10737412422: Input/output error
  /dev/vg0/snapshot_1: read failed after 0 of 4096 at 0: Input/output error
  /dev/vg0/snapshot_1: read failed after 0 of 4096 at 4096: Input/output error
  LV          VG  Attr       LSize  Pool Origin   Data%  Meta%  Move Log Cpy%Sync Convert
  root        cl  -wi-ao---- 17.00g
  swap        cl  -wi-ao----  2.00g
  backups     vg0 -wi-ao----  9.99g
  projects    vg0 owi-aos--- 17.81g
  snapshot_1 vg0 swi-I-s---  1.00g      projects 100.00

Nếu chúng ta có Source volume có kích thước là 10GB thì chúng ta cũng nên tạo snapshot có dung lượng 10GB để đủ không gian chứa các thay đổi của Source volume.

    Chú ý: Dung lượng Snapshot tăng lên đúng bằng dung lượng tạo mới trên LV. Không thể tạo Snapshot mới ghi đè lên Snapshot cũ. Trường hợp bạn có 2 Snapshot cho cùng 1 ổ LV thì dữ liệu mới cũng được ghi cả vào 2 ổ Snapshot.

3.1.2. Tăng dung lượng snapshot trong lvm

Chúng ta cần mở rộng kích thước của snapshot, chúng ta có thể thực hiện bằng cách sử dụng:
